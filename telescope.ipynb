{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn classification using kNN and Naive Bayes \n",
    "\n",
    "This lesson uses the [MAGIC Gamma telescope data](course_datasets.md#magic-gamma-telecope).  It is a classifcation task.  It first cleans and prepares the data then uses two scikit-learn classifiers, k nearest mneighbours (kNN) and Naive Bayes to predict.\n",
    "\n",
    "It is based on the tutorial on the YouTube Machine Learning for Everybody channel [here](https://youtu.be/i_LwzRVP7bg?si=if0Cv0izdY4TIcsS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip  install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    \"fLength\",\n",
    "    \"fWidth\",\n",
    "    \"fSize\",\n",
    "    \"fConc\",\n",
    "    \"fConc1\",\n",
    "    \"fAsym\",\n",
    "    \"fM3Long\",\n",
    "    \"fM3Trans\",\n",
    "    \"fAlpha\",\n",
    "    \"fDist\",\n",
    "    \"class\",\n",
    "]\n",
    "df = pd.read_csv(\"data/magic04.data\", header=None, names=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chack that the label only has two values: g (gamma) and h (hadron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Convert the label to an integer: g ->1, h -> 0.\n",
    "Numeric laels are required by the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)\n",
    "# df['class'].unique()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the independent variables, show the probability distrution of both gamma (in blue) and hadron (in red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in col_names[:-1]:\n",
    "    plt.hist(\n",
    "        df[df[\"class\"] == 1][col_name],\n",
    "        bins=20,\n",
    "        alpha=0.7,\n",
    "        label=\"gamma\",\n",
    "        color=\"blue\",\n",
    "        density=True,\n",
    "    )\n",
    "    plt.hist(\n",
    "        df[df[\"class\"] == 0][col_name],\n",
    "        bins=20,\n",
    "        alpha=0.7,\n",
    "        label=\"hadron\",\n",
    "        color=\"red\",\n",
    "        density=True,\n",
    "    )\n",
    "    plt.title(col_name)\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(col_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset1(dataframe):\n",
    "    \"\"\"Scale the values in each column to a standard normal distribution (mean of 0 and standard distribution of 1)\"\"\"\n",
    "    for col_name in col_names[:-1]:\n",
    "        dataframe[col_name] = (\n",
    "            dataframe[col_name] - dataframe[col_name].mean()\n",
    "        ) / dataframe[col_name].std()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset_alt(dataframe, oversample=False):\n",
    "    X = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    if oversample:\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "\n",
    "    data = np.hstack((X, y.reshape(-1, 1)))\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick check to understand exactly what reshape(-1,1) does to an 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "test_y2 = test_y.reshape(-1, 1)\n",
    "test_y, test_y.shape, test_y2, test_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train = scale_dataset_alt(train, oversample=True)\n",
    "valid, X_valid, y_valid = scale_dataset_alt(valid, oversample=False)\n",
    "test, X_test, y_test = scale_dataset_alt(test, oversample=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "k nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
