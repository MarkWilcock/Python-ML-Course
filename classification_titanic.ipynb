{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Examples - Titanic Dataset\n",
    "\n",
    "This lesson uses the [Titanic dataset](course_datasets.md#titanic).  It predicts Survival based on passenger class, sex, fare, embarkation, fare band, using logistic regression and decision tree classifiers.\n",
    "\n",
    "Steps\n",
    "* Load data into pandas\n",
    "* Clean data (select columns), remove any rows with missing values\n",
    "* Encode data (convert string columns into numbers, required by model). One-hot Ordinal (later) for passenger class\n",
    "* Encode label column (Died ->0, Survived ->1)\n",
    "* Split data into training and test sections\n",
    "* Build logistic regression model, fit on training data an predict on test data\n",
    "* Evaluate models with a confusion matrix\n",
    "* Build decision tree model, fit on training data and predict on test data. \n",
    "* Show decision tree model graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nimport joblib"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the titanic data from a CSV file on a public URL into a pandas DataFrame\n",
    "This version of the dataset has already been cleaned to some extent: it has  columns form Adult Or Child, and Is Age missing, based on the Age column.  It also has a FareBand column based on the Fare column. The original Name column has been split into Title, Surname and Other Names columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_url = 'https://zomalextrainingstorage.blob.core.windows.net/datasets/misc/titanic.csv'\n",
    "titanic_url = 'https://raw.githubusercontent.com/MarkWilcock/CourseDatasets/main/Misc%20Datasets/Titanic%20Passenger.csv'\n",
    "df = pd.read_csv(titanic_url) # read the data\n",
    "df.head(5) # show the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the columns of interest, and rename these in a consistent snake_case (Pythonic) style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_slim = df[['Survival', 'Title', 'Passenger Class', 'Gender', 'Embarked', 'FareBand', 'Adult Or Child']]\ndf_slim.columns = ['survival', 'title', 'pass_class', 'gender', 'embarked', 'fareband', 'adult_or_child']\ndf_slim.head(5)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the categorical columns with a one hot encoder. See [this explainer article](https://www.geeksforgeeks.org/ml-one-hot-encoding/) and the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = ['title', 'gender', 'embarked', 'fareband', 'adult_or_child']\n",
    "categorical_encoders = OneHotEncoder(sparse_output=False)\n",
    "categorical_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal data are categorical data with a natural rank order but the distances between the categories are uneven or unknown. e.g. cool, warm, hot.  In this dataset, the pass_class (passenger class) column contains ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_columns =  ['pass_class']\n",
    "pass_class_values = ['1st', '2nd', '3rd']\n",
    "ordinal_encoders = OrdinalEncoder(categories=[pass_class_values]) \n",
    "ordinal_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ColumnTransformer lets us assemble the transforms on all the dataset columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "        ('cat', categorical_encoders, category_columns),\n",
    "        ('ord', ordinal_encoders, ordinal_columns)\n",
    "        ], \n",
    "        remainder = 'drop')\n",
    "ct.set_output(transform='pandas')\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the standard name for the transformed data of features (independent variables)\n",
    "X = ct.fit_transform(df_slim)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array of labels from the survival column.  survival is a text column (with values Died and Survived), and is transformed to an array of numbers either 0 (Died) and 1 (Survived)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "label_encoder = LabelEncoder()\ny = label_encoder.fit_transform(df_slim['survival'])\ny[:5] # show the first 5 elements of y"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info method shows the column names of the data transformed by the column encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train.info():\\n {X_train.info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression model\n",
    "Build and fit the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(X_train, y_train)\n",
    "predictions_LR = model_LR.predict(X_test)\n",
    "predictions_LR[:5] # show the first 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate using standard metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report\\n',  classification_report(y_test, predictions_LR))\n",
    "print(f'f1 score\\n {f1_score(y_test, predictions_LR):3.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand how well the model is performing with a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model\n",
    "Build and fit the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT = DecisionTreeClassifier(max_depth=4)\n",
    "model_DT.fit(X_train, y_train)\n",
    "model_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_DT = model_DT.predict(X_test)\n",
    "predictions_DT[:5] # show the first 5 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Visualise the decision tree model using scikit-learn's built-in `plot_tree` function."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(20, 10))\nplot_tree(model_DT,\n          feature_names=X.columns,\n          class_names=['Died', 'Survived'],\n          filled=True,\n          rounded=True,\n          ax=ax)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the model in case we want to rerun without retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_DT, 'outputs/titanic_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}